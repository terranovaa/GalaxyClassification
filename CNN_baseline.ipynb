{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras.optimizers as optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization, Input\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras import regularizers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_height = 64\n",
    "input_width = 64\n",
    "batch_size = 64\n",
    "\n",
    "# TODO: find best parameters using the display_data_augmentation_sample jupyter notebook\n",
    "rescale = True\n",
    "if rescale:\n",
    "    rescale_size=1./255\n",
    "else:\n",
    "    rescale_size=1\n",
    "augmentation=True\n",
    "\n",
    "rotation_range=40\n",
    "width_shift_range=0.2\n",
    "height_shift_range=0.2\n",
    "shear_range=0.2\n",
    "zoom_range=0.2\n",
    "horizontal_flip=True\n",
    "fill_mode='nearest'\n",
    "# consider also stride (>1), type of pooling (Max, Avg), padding (same, valid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# best loss function for multi-class classification, measures the distance between two probability distributions\n",
    "# the probability distribution of the output of the network and the true distribution of the labels\n",
    "loss_function='categorical_crossentropy'\n",
    "\n",
    "metrics=['accuracy']\n",
    "optimizer='rmsprop'\n",
    "optimizer_learning_rate=1e-4\n",
    "epochs=5\n",
    "batch_size=20\n",
    "regularizer=regularizers.l1_l2(l1=0.001, l2=0.001) # simultaneous l1 and l2, add 0.001*weight_coefficient_value + 0.001 * 1/2*weight^2\n",
    "\n",
    "if optimizer == 'rmsprop':\n",
    "    optimizer=optimizers.RMSprop(learning_rate=optimizer_learning_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Holdout method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'TRAIN_PATH' : os.path.join('workspace', 'images', 'train'),\n",
    "    'TEST_PATH' : os.path.join('workspace', 'images','test'),\n",
    "    'EVAL_PATH' : os.path.join('workspace', 'images','eval'),\n",
    "    'IMAGES_PATH': os.path.join('workspace','images','all'),\n",
    "    'ANNOTATION_PATH': os.path.join('workspace','annotations'),\n",
    "    'LOG_DIR' : os.path.join('model', 'log_dir', 'train')\n",
    " }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create paths\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove all files already present for an old holdout method execution\n",
    "for file in os.listdir(paths[\"TRAIN_PATH\"]):\n",
    "    if file != \".DS_Store\":\n",
    "        os.remove(os.path.join(paths[\"TRAIN_PATH\"], file))\n",
    "for file in os.listdir(paths[\"TEST_PATH\"]):\n",
    "    if file != \".DS_Store\":\n",
    "        os.remove(os.path.join(paths[\"TEST_PATH\"], file))\n",
    "for file in os.listdir(paths[\"EVAL_PATH\"]):\n",
    "    if file != \".DS_Store\":\n",
    "        os.remove(os.path.join(paths[\"EVAL_PATH\"], file))\n",
    "\n",
    "df = pd.read_csv(os.path.join(paths['ANNOTATION_PATH'],\"annotations.csv\"))\n",
    "df = df.dropna()\n",
    "\n",
    "# split in training set (90%) and test set (10%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df, test_size=0.1, shuffle=True)\n",
    "print(\"Train size: \" + str(len(X_train)))\n",
    "\n",
    "for index, row in X_train.iterrows():\n",
    "    shutil.copy(os.path.join(paths[\"IMAGES_PATH\"],row['Path']),\n",
    "                os.path.join(paths[\"TRAIN_PATH\"],row['Path']))\n",
    "\n",
    "for index, row in X_test.iterrows():\n",
    "    shutil.copy(os.path.join(paths[\"IMAGES_PATH\"],row['Path']),\n",
    "                os.path.join(paths[\"TEST_PATH\"],row['Path']))\n",
    "\n",
    "# split the training set into the final training set (80%) and validation set (20%)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "print(\"Test size: \" + str(len(X_test)))\n",
    "print(\"Eval size: \" + str(len(X_eval)))\n",
    "\n",
    "for _, row in X_eval.iterrows():\n",
    "    shutil.copy(os.path.join(paths[\"IMAGES_PATH\"],row['Path']),\n",
    "                os.path.join(paths[\"EVAL_PATH\"],row['Path']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training set image data generator\n",
    "if augmentation:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "          rescale=rescale_size,\n",
    "          rotation_range=rotation_range,\n",
    "          width_shift_range=width_shift_range,\n",
    "          height_shift_range=height_shift_range,\n",
    "          shear_range=shear_range,\n",
    "          zoom_range=zoom_range,\n",
    "          horizontal_flip=horizontal_flip,\n",
    "          fill_mode=fill_mode)\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    # to perform normalization we should never use information coming from the test set, only training set\n",
    "\n",
    "train_dir=paths['TRAIN_PATH']\n",
    "\n",
    "# TODO: Consider if the output should be normalized\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# validation set image data generator\n",
    "val_datagen = ImageDataGenerator(rescale=rescale_size) # it should not be augmented\n",
    "\n",
    "validation_dir=paths['EVAL_PATH']\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(validation_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Model creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 64, 64, 16)        448       \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 64, 64, 16)        0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 64, 64, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 32, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " activation_45 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 32, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 16)                65552     \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 16)                0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,721\n",
      "Trainable params: 89,465\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Function used to create the CNN structure used for regression\n",
    "def create_cnn(width, height, depth, num_classes,filters=(16, 32, 64)):\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    model = models.Sequential()\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # first CONV layer set appropriately\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(f, (3, 3), activation=\"relu\", padding=\"same\", kernel_regularizer=regularizer, input_shape=inputShape))\n",
    "        else:\n",
    "            model.add(Conv2D(f, (3, 3), activation=\"relu\", padding=\"same\", kernel_regularizer=regularizer))\n",
    "        # size of the patches typically 3x3 or 5x5\n",
    "        # determine if we need to change padding or stride, with padding = same we are able to center convolutional windows around every input tile, in order to have always the same size of the input image\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # FLATTEN => FC => RELU => BN => DROPOUT\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation=\"relu\")) # consider if we need to add this dense layer before with more units, such as 64 in order to shrink in two different stages, depends on the outpout size of flatten\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = create_cnn(input_width, input_height, 3, 8, (8,16))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# steps_per_epoch: number of batches to be drawn from the generator after assuming epoch over\n",
    "# epochs: number of epochs\n",
    "# validation_steps: how many batches to draw from the validation generator for evaluation\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=7,\n",
    "      epochs=10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation ACC')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# smooth curves if they look noisy\n",
    "# replace each point with an exponential moving average of the previous points\n",
    "def smooth_curve(points, factor=0.8):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs,\n",
    "         smooth_curve(acc), 'r', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), 'r', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# display average, the model may improve even if not reflected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Early stopping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "\n",
    "callbacks_list = [\n",
    "        # interrupts training when accuracy has stopped improving accuracy on the validation set for at least 3+1=4 epochs\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='acc', # should be part of the metrics specific during compilation\n",
    "            patience=3,\n",
    "        ),\n",
    "        # save the current weights after every epoch\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(paths['MODELS'],'CNN_baseline.h5'),\n",
    "            monitor='val_loss', # do not overwrite until val_loss is improved\n",
    "            save_best_only=True\n",
    "        ),\n",
    "        # monitor the model's validation loss and reduce the LR when the validation loss has stopped improving, effective strategy to escape local minima\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2, # divides LR by 5 when triggered\n",
    "            patience=3 # called when stopped improving for 3 epochs\n",
    "        ),\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=paths['LOG_DIR'],\n",
    "            write_graph=True,\n",
    "            histogram_freq=1 # record activation histograms every 1 epoch\n",
    "        )\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=3,\n",
    "      epochs=5,\n",
    "      validation_data=validation_generator,\n",
    "      callbacks=callbacks_list,\n",
    "      validation_steps=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Model testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dir=paths[\"TEST_PATH\"]\n",
    "test_datagen = ImageDataGenerator(rescale=rescale_size) # it should not be augmented\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "# if performances are much wors than validation ones, during hyperparameter optimization (when done) the process has overfitted the validdation set, if so go to a more clear protocol such as Kfold CV\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=2)\n",
    "print('test acc:', test_acc)\n",
    "print('test loss:', test_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: is it balanced? If not consider ROC AUC for example, FPR, TPR, and others"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. Model exportation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/CNN_baseline.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9. Plot model as graph of layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install pydot\n",
    "! brew install graphviz # for MacOS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file='model.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
