{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'APIMODEL_PATH': os.path.join('models'),\n",
    "    'ANNOTATION_PATH': os.path.join('workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('workspace','images'),\n",
    "    'CHECKPOINT_PATH': os.path.join('workspace','models',CUSTOM_MODEL_NAME)\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 1. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(EVALUATION_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
   },
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqTV2jGBpfDH"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See tensorboard results\n",
    "# Go to the eval directory and use the following command, then visit localhost:6006\n",
    "command = \"tensorboard --logdir=.\"\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "# 2. Load the train model from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "# Build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "checkpoint_index=91 # set the checkpoint index\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-'+str(checkpoint_index))).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmsmbBZpfDI"
   },
   "source": [
    "# 3. Perform prediction on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install opencv-python\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBDbIhNapfDI"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# loop through all the test set and perform the prediction\n",
    "for image in os.listdir(os.path.join(paths['IMAGE_PATH'],'test')):\n",
    "    if not image.endswith(\".jpg\"):\n",
    "        continue\n",
    "    img = cv2.imread(os.path.join(paths['IMAGE_PATH'],'test',image))\n",
    "    image_np = np.array(img)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    try:\n",
    "        detections = detect_fn(input_tensor)\n",
    "    except:\n",
    "        print(\"Exception\")\n",
    "        continue\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    # set the proper arguments to change results\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=1,\n",
    "                min_score_thresh=.6,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    key = cv2.waitKey(3000)\n",
    "    if key == 27: #ESC to exit loop\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Detection on test videos (Find galaxy videos and test it)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "video_path='workspace/raw_data/'\n",
    "for video in os.listdir(video_path):\n",
    "    print(\"Processing video\", video)\n",
    "    vcapture = cv2.VideoCapture(video_path+video)\n",
    "    width = int(vcapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = vcapture.get(cv2.CAP_PROP_FPS)\n",
    "    file_name = \"splash_{:%Y%m%dT%H%M%S}.avi\".format(datetime.datetime.now())\n",
    "    vwriter = cv2.VideoWriter(file_name, cv2.VideoWriter_fourcc(*'MJPG'), fps, (width, height))\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "        success, img = vcapture.read()\n",
    "        if success:\n",
    "            count += 1\n",
    "            image_np = np.array(img)\n",
    "            input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "            detections = detect_fn(input_tensor)\n",
    "            num_detections = int(detections.pop('num_detections'))\n",
    "            detections = {key: value[0, :num_detections].numpy()\n",
    "                          for key, value in detections.items()}\n",
    "            detections['num_detections'] = num_detections\n",
    "            detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "            label_id_offset = 1\n",
    "            image_np_with_detections = image_np.copy()\n",
    "            viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                        image_np_with_detections,\n",
    "                        detections['detection_boxes'],\n",
    "                        detections['detection_classes']+label_id_offset,\n",
    "                        detections['detection_scores'],\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=True,\n",
    "                        max_boxes_to_draw=1,\n",
    "                        min_score_thresh=.95,\n",
    "                        agnostic_mode=False)\n",
    "            vwriter.write(image_np_with_detections)\n",
    "            if count > 250:\n",
    "                break\n",
    "    vwriter.release()\n",
    "    print(\"Saved to \", file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "odod",
   "language": "python",
   "display_name": "odod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
