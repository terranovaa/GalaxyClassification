{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display the visual pattern that each filter is meant to respond to, apllying gradient ascent in the input space, maximizing the response of a specific filter and calculating the input images the filter is maximally responsive to\n",
    "# they tell how a convolutional layer see the world, each layer see the input as a combination of these filters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# customized metrics\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(\"..\",\"models\",\"CNN_dropout_batch_bigger_class_weights.h5\"),custom_objects = {\"precision\": precision, \"recall\": recall})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# turn it into a displayable image\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # mean: 0, std: 1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clips to [0,1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# runs gradient ascent for a certain number of steps\n",
    "steps = 40\n",
    "\n",
    "def generate_pattern(layer_name, filter_index, size=69):\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "    # gradient of the loss wrt to the model's input\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5) # normalize by dividing by its L2 norm\n",
    "    iterate = K.function([model.input], [loss, grads])\n",
    "    # starts from a gray image with some noise\n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "    step = 1. # magnitude of each gradient update\n",
    "    for i in range(steps):\n",
    "        # obtain the loss value and gradient value\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step # adjust the input image in order to maximize the loss\n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pattern to which the i-th channel in layer is responsive\n",
    "i = 7\n",
    "layer = \"conv2d_e\"\n",
    "plt.imshow(generate_pattern(layer, i))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# grid of all filter response patterns in a layer\n",
    "\n",
    "# for simplicity the first n filters of the layer set, obtaining a grid of the n filter patterns\n",
    "layer_name = 'conv2d_2'\n",
    "size = 69\n",
    "margin = 5\n",
    "results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3))\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        print(i, j)\n",
    "        filter_img = generate_pattern(layer_name, i + (j * 8))\n",
    "        horizontal_start = i * size + i * margin\n",
    "        horizontal_end = horizontal_start + size\n",
    "        vertical_start = j * size + j * margin\n",
    "        vertical_end = vertical_start + size\n",
    "        results[horizontal_start: horizontal_end,vertical_start: vertical_end, :] = filter_img\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
