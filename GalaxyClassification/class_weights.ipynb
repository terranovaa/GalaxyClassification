{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "import keras as keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.optimizers as optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "input_height = 69\n",
    "input_width = 69\n",
    "batch_size = 64\n",
    "\n",
    "# TODO: find best parameters using the display_data_augmentation_sample jupyter notebook\n",
    "rescale = True\n",
    "if rescale:\n",
    "    rescale_size=1./255\n",
    "else:\n",
    "    rescale_size=1\n",
    "augmentation=True\n",
    "\n",
    "rotation_range=40\n",
    "width_shift_range=0.2\n",
    "height_shift_range=0.1\n",
    "shear_range=0.2\n",
    "zoom_range=0.2\n",
    "horizontal_flip=True\n",
    "fill_mode='nearest'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "# best loss function for multi-class classification, measures the distance between two probability distributions\n",
    "# the probability distribution of the output of the network and the true distribution of the labels\n",
    "loss_function='categorical_crossentropy'\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    tf.keras.metrics.Accuracy(name=\"accuracy\", dtype=None)\n",
    "]\n",
    "optimizer='rmsprop'\n",
    "optimizer_learning_rate=1e-4\n",
    "epochs=100\n",
    "batch_size=32\n",
    "#regularizer=regularizers.l1_l2(l1=0.001, l2=0.001) # simultaneous l1 and l2, add 0.001*weight_coefficient_value + 0.001 * 1/2*weight^2\n",
    "\n",
    "if optimizer == 'rmsprop':\n",
    "    optimizer=optimizers.RMSprop(learning_rate=optimizer_learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "\n",
    "paths = {\n",
    "    'TRAIN_PATH' : os.path.join('data','workspace', 'images', 'train'),\n",
    "    'TEST_PATH' : os.path.join('data','workspace', 'images','test'),\n",
    "    'EVAL_PATH' : os.path.join('data','workspace', 'images','eval'),\n",
    "    'IMAGES_PATH': os.path.join('data','workspace','images','all'),\n",
    "    'ANNOTATION_PATH': os.path.join('data','workspace','annotations','final_annotations.csv'),\n",
    "    'LOG_DIR' : os.path.join('data','model', 'log_dir')\n",
    " }\n",
    "\n",
    "annotations = pd.read_csv(paths['ANNOTATION_PATH'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3461, 1: 6997, 2: 6292, 3: 349, 4: 1534, 6: 589, 7: 1121, 8: 906, 9: 519}\n"
     ]
    }
   ],
   "source": [
    "#get number of images for each class\n",
    "number_per_class = annotations.groupby('Class').count()\n",
    "imgs_per_class = number_per_class.to_dict()['Path']\n",
    "print(imgs_per_class)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2488, 1: 5017, 2: 4551, 3: 257, 4: 1122, 5: 415, 6: 797, 7: 646, 8: 381}\n"
     ]
    }
   ],
   "source": [
    "#compute number of images in training set\n",
    "imgs_per_label = dict()\n",
    "for i in range(9):\n",
    "  path = os.path.join(paths['TRAIN_PATH'],str(i))\n",
    "  #compute number of images for each folder representing a label\n",
    "  n_images = len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n",
    "  imgs_per_label[i] = n_images\n",
    "\n",
    "print(imgs_per_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15674\n",
      "{0: 0.6999821364773133, 1: 0.3471308661661462, 2: 0.3826753582851144, 3: 6.7764807609165585, 4: 1.5521885521885521, 5: 4.196519410977242, 6: 2.1851387146242853, 7: 2.695906432748538, 8: 4.571011956838729}\n"
     ]
    }
   ],
   "source": [
    "#weight computation\n",
    "\n",
    "#number of classes\n",
    "NUM_CLASSES = 9\n",
    "\n",
    "#get number of total images\n",
    "tot_images = sum(list(imgs_per_label.values()))\n",
    "print(tot_images)\n",
    "\n",
    "#dictionary storing weights for each class\n",
    "#weight[i] = number_total_samples / number_total_classes * num_samples_class_i\n",
    "weights = dict([ (class_label , tot_images/(NUM_CLASSES * n_images)) for class_label, n_images in imgs_per_label.items()])\n",
    "\n",
    "print(weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15674 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# training set image data generator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "if augmentation:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "          rescale=rescale_size,\n",
    "          rotation_range=rotation_range,\n",
    "          width_shift_range=width_shift_range,\n",
    "          height_shift_range=height_shift_range,\n",
    "          shear_range=shear_range,\n",
    "          zoom_range=zoom_range,\n",
    "          horizontal_flip=horizontal_flip,\n",
    "          fill_mode=fill_mode)\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    # to perform normalization we should never use information coming from the test set, only training set\n",
    "\n",
    "train_dir=paths['TRAIN_PATH']\n",
    "\n",
    "# TODO: Consider if the output should be normalized\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3919 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# validation set image data generator\n",
    "val_datagen = ImageDataGenerator(rescale=rescale_size) # it should not be augmented\n",
    "\n",
    "validation_dir=paths['EVAL_PATH']\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(validation_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Model creation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 69, 69, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 34, 34, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 34, 34, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9248)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                591936    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 585       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 597,609\n",
      "Trainable params: 597,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Function used to create the CNN structure used for regression\n",
    "def create_cnn(width, height, depth, num_classes,filters=(16, 32, 64)):\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    model = models.Sequential()\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # first CONV layer set appropriately\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(f, (3, 3), activation=\"relu\", padding=\"same\", input_shape=inputShape))\n",
    "        else:\n",
    "            model.add(Conv2D(f, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "        # size of the patches typically 3x3 or 5x5\n",
    "        # determine if we need to change padding or stride, with padding = same we are able to center convolutional windows around every input tile, in order to have always the same size of the input image\n",
    "        # model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # FLATTEN => FC => RELU => BN => DROPOUT\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation=\"relu\")) # consider if we need to add this dense layer before with more units, such as 64 in order to shrink in two different stages, depends on the outpout size of flatten\n",
    "    #model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = create_cnn(input_width, input_height, 3, 9, (16,32))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Model training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3919\n"
     ]
    }
   ],
   "source": [
    "n_images_eval = 0\n",
    "for i in range(9):\n",
    "  path = os.path.join(paths['EVAL_PATH'],str(i))\n",
    "  #compute number of images in each eval folder and sum it up\n",
    "  n_images_eval = n_images_eval + len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n",
    "\n",
    "print(n_images_eval)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "490/490 [==============================] - 107s 218ms/step - loss: 1.7102 - fn: 15266.0000 - fp: 333.0000 - tn: 125059.0000 - tp: 408.0000 - precision: 0.5506 - recall: 0.0260 - val_loss: 1.5945 - val_fn: 3799.0000 - val_fp: 90.0000 - val_tn: 31262.0000 - val_tp: 120.0000 - val_precision: 0.5714 - val_recall: 0.0306\n",
      "Epoch 2/100\n",
      "490/490 [==============================] - 88s 180ms/step - loss: 1.6568 - fn: 15143.0000 - fp: 423.0000 - tn: 124969.0000 - tp: 531.0000 - precision: 0.5566 - recall: 0.0339 - val_loss: 1.5509 - val_fn: 3675.0000 - val_fp: 175.0000 - val_tn: 31177.0000 - val_tp: 244.0000 - val_precision: 0.5823 - val_recall: 0.0623\n",
      "Epoch 3/100\n",
      "490/490 [==============================] - 87s 177ms/step - loss: 1.6159 - fn: 14904.0000 - fp: 444.0000 - tn: 124948.0000 - tp: 770.0000 - precision: 0.6343 - recall: 0.0491 - val_loss: 1.4825 - val_fn: 3587.0000 - val_fp: 181.0000 - val_tn: 31171.0000 - val_tp: 332.0000 - val_precision: 0.6472 - val_recall: 0.0847\n",
      "Epoch 4/100\n",
      "490/490 [==============================] - 88s 180ms/step - loss: 1.5806 - fn: 14630.0000 - fp: 548.0000 - tn: 124844.0000 - tp: 1044.0000 - precision: 0.6558 - recall: 0.0666 - val_loss: 1.4726 - val_fn: 3533.0000 - val_fp: 184.0000 - val_tn: 31168.0000 - val_tp: 386.0000 - val_precision: 0.6772 - val_recall: 0.0985\n",
      "Epoch 5/100\n",
      "490/490 [==============================] - 88s 179ms/step - loss: 1.5418 - fn: 14389.0000 - fp: 640.0000 - tn: 124752.0000 - tp: 1285.0000 - precision: 0.6675 - recall: 0.0820 - val_loss: 1.3598 - val_fn: 3234.0000 - val_fp: 380.0000 - val_tn: 30972.0000 - val_tp: 685.0000 - val_precision: 0.6432 - val_recall: 0.1748\n",
      "Epoch 6/100\n",
      "490/490 [==============================] - 79s 162ms/step - loss: 1.5149 - fn: 14080.0000 - fp: 797.0000 - tn: 124595.0000 - tp: 1594.0000 - precision: 0.6667 - recall: 0.1017 - val_loss: 1.5491 - val_fn: 3405.0000 - val_fp: 273.0000 - val_tn: 31079.0000 - val_tp: 514.0000 - val_precision: 0.6531 - val_recall: 0.1312\n",
      "Epoch 7/100\n",
      "490/490 [==============================] - 87s 177ms/step - loss: 1.4839 - fn: 13843.0000 - fp: 887.0000 - tn: 124505.0000 - tp: 1831.0000 - precision: 0.6737 - recall: 0.1168 - val_loss: 1.3238 - val_fn: 3091.0000 - val_fp: 499.0000 - val_tn: 30853.0000 - val_tp: 828.0000 - val_precision: 0.6240 - val_recall: 0.2113\n",
      "Epoch 8/100\n",
      "490/490 [==============================] - 88s 180ms/step - loss: 1.4689 - fn: 13669.0000 - fp: 970.0000 - tn: 124422.0000 - tp: 2005.0000 - precision: 0.6739 - recall: 0.1279 - val_loss: 1.3488 - val_fn: 3249.0000 - val_fp: 315.0000 - val_tn: 31037.0000 - val_tp: 670.0000 - val_precision: 0.6802 - val_recall: 0.1710\n",
      "Epoch 9/100\n",
      "490/490 [==============================] - 86s 176ms/step - loss: 1.4351 - fn: 13411.0000 - fp: 1098.0000 - tn: 124294.0000 - tp: 2263.0000 - precision: 0.6733 - recall: 0.1444 - val_loss: 1.2980 - val_fn: 3172.0000 - val_fp: 341.0000 - val_tn: 31011.0000 - val_tp: 747.0000 - val_precision: 0.6866 - val_recall: 0.1906\n",
      "Epoch 10/100\n",
      "490/490 [==============================] - 87s 177ms/step - loss: 1.4276 - fn: 13301.0000 - fp: 1127.0000 - tn: 124265.0000 - tp: 2373.0000 - precision: 0.6780 - recall: 0.1514 - val_loss: 1.3244 - val_fn: 3015.0000 - val_fp: 456.0000 - val_tn: 30896.0000 - val_tp: 904.0000 - val_precision: 0.6647 - val_recall: 0.2307\n",
      "Epoch 11/100\n",
      "490/490 [==============================] - 88s 180ms/step - loss: 1.4097 - fn: 13138.0000 - fp: 1260.0000 - tn: 124132.0000 - tp: 2536.0000 - precision: 0.6681 - recall: 0.1618 - val_loss: 1.2153 - val_fn: 3001.0000 - val_fp: 412.0000 - val_tn: 30940.0000 - val_tp: 918.0000 - val_precision: 0.6902 - val_recall: 0.2342\n",
      "Epoch 12/100\n",
      "490/490 [==============================] - 73s 150ms/step - loss: 1.3996 - fn: 13121.0000 - fp: 1322.0000 - tn: 124070.0000 - tp: 2553.0000 - precision: 0.6588 - recall: 0.1629 - val_loss: 1.2295 - val_fn: 2926.0000 - val_fp: 479.0000 - val_tn: 30873.0000 - val_tp: 993.0000 - val_precision: 0.6746 - val_recall: 0.2534\n",
      "Epoch 13/100\n",
      "490/490 [==============================] - 89s 181ms/step - loss: 1.3865 - fn: 12986.0000 - fp: 1315.0000 - tn: 124077.0000 - tp: 2688.0000 - precision: 0.6715 - recall: 0.1715 - val_loss: 1.2485 - val_fn: 2795.0000 - val_fp: 597.0000 - val_tn: 30755.0000 - val_tp: 1124.0000 - val_precision: 0.6531 - val_recall: 0.2868\n",
      "Epoch 14/100\n",
      "490/490 [==============================] - 437s 893ms/step - loss: 1.3948 - fn: 12879.0000 - fp: 1427.0000 - tn: 123965.0000 - tp: 2795.0000 - precision: 0.6620 - recall: 0.1783 - val_loss: 1.2049 - val_fn: 2775.0000 - val_fp: 609.0000 - val_tn: 30743.0000 - val_tp: 1144.0000 - val_precision: 0.6526 - val_recall: 0.2919\n",
      "Epoch 15/100\n",
      "490/490 [==============================] - 535s 1s/step - loss: 1.3824 - fn: 12824.0000 - fp: 1388.0000 - tn: 124004.0000 - tp: 2850.0000 - precision: 0.6725 - recall: 0.1818 - val_loss: 1.2855 - val_fn: 2880.0000 - val_fp: 513.0000 - val_tn: 30839.0000 - val_tp: 1039.0000 - val_precision: 0.6695 - val_recall: 0.2651\n",
      "Epoch 16/100\n",
      "490/490 [==============================] - 517s 1s/step - loss: 1.3685 - fn: 12687.0000 - fp: 1418.0000 - tn: 123974.0000 - tp: 2987.0000 - precision: 0.6781 - recall: 0.1906 - val_loss: 1.2496 - val_fn: 2788.0000 - val_fp: 640.0000 - val_tn: 30712.0000 - val_tp: 1131.0000 - val_precision: 0.6386 - val_recall: 0.2886\n",
      "Epoch 17/100\n",
      "490/490 [==============================] - 652s 1s/step - loss: 1.3619 - fn: 12632.0000 - fp: 1502.0000 - tn: 123890.0000 - tp: 3042.0000 - precision: 0.6695 - recall: 0.1941 - val_loss: 1.2335 - val_fn: 2976.0000 - val_fp: 418.0000 - val_tn: 30934.0000 - val_tp: 943.0000 - val_precision: 0.6929 - val_recall: 0.2406\n",
      "Epoch 18/100\n",
      "490/490 [==============================] - 468s 956ms/step - loss: 1.3633 - fn: 12599.0000 - fp: 1568.0000 - tn: 123824.0000 - tp: 3075.0000 - precision: 0.6623 - recall: 0.1962 - val_loss: 1.1752 - val_fn: 2810.0000 - val_fp: 529.0000 - val_tn: 30823.0000 - val_tp: 1109.0000 - val_precision: 0.6770 - val_recall: 0.2830\n",
      "Epoch 19/100\n",
      "490/490 [==============================] - 568s 1s/step - loss: 1.3466 - fn: 12453.0000 - fp: 1587.0000 - tn: 123805.0000 - tp: 3221.0000 - precision: 0.6699 - recall: 0.2055 - val_loss: 1.1809 - val_fn: 2652.0000 - val_fp: 709.0000 - val_tn: 30643.0000 - val_tp: 1267.0000 - val_precision: 0.6412 - val_recall: 0.3233\n",
      "Epoch 20/100\n",
      "490/490 [==============================] - 210s 428ms/step - loss: 1.3391 - fn: 12381.0000 - fp: 1638.0000 - tn: 123754.0000 - tp: 3293.0000 - precision: 0.6678 - recall: 0.2101 - val_loss: 1.1874 - val_fn: 2704.0000 - val_fp: 657.0000 - val_tn: 30695.0000 - val_tp: 1215.0000 - val_precision: 0.6490 - val_recall: 0.3100\n",
      "Epoch 21/100\n",
      "490/490 [==============================] - 685s 1s/step - loss: 1.3315 - fn: 12389.0000 - fp: 1725.0000 - tn: 123667.0000 - tp: 3285.0000 - precision: 0.6557 - recall: 0.2096 - val_loss: 1.2331 - val_fn: 3006.0000 - val_fp: 391.0000 - val_tn: 30961.0000 - val_tp: 913.0000 - val_precision: 0.7002 - val_recall: 0.2330\n",
      "Epoch 22/100\n",
      "490/490 [==============================] - 853s 2s/step - loss: 1.3352 - fn: 12379.0000 - fp: 1731.0000 - tn: 123661.0000 - tp: 3295.0000 - precision: 0.6556 - recall: 0.2102 - val_loss: 1.1670 - val_fn: 2742.0000 - val_fp: 583.0000 - val_tn: 30769.0000 - val_tp: 1177.0000 - val_precision: 0.6687 - val_recall: 0.3003\n",
      "Epoch 23/100\n",
      "490/490 [==============================] - 784s 2s/step - loss: 1.3204 - fn: 12308.0000 - fp: 1710.0000 - tn: 123682.0000 - tp: 3366.0000 - precision: 0.6631 - recall: 0.2148 - val_loss: 1.1544 - val_fn: 2640.0000 - val_fp: 665.0000 - val_tn: 30687.0000 - val_tp: 1279.0000 - val_precision: 0.6579 - val_recall: 0.3264\n",
      "Epoch 24/100\n",
      "490/490 [==============================] - 895s 2s/step - loss: 1.3223 - fn: 12121.0000 - fp: 1814.0000 - tn: 123578.0000 - tp: 3553.0000 - precision: 0.6620 - recall: 0.2267 - val_loss: 1.2461 - val_fn: 2953.0000 - val_fp: 459.0000 - val_tn: 30893.0000 - val_tp: 966.0000 - val_precision: 0.6779 - val_recall: 0.2465\n",
      "Epoch 25/100\n",
      "490/490 [==============================] - 734s 2s/step - loss: 1.3085 - fn: 12116.0000 - fp: 1851.0000 - tn: 123541.0000 - tp: 3558.0000 - precision: 0.6578 - recall: 0.2270 - val_loss: 1.1713 - val_fn: 2755.0000 - val_fp: 525.0000 - val_tn: 30827.0000 - val_tp: 1164.0000 - val_precision: 0.6892 - val_recall: 0.2970\n",
      "Epoch 26/100\n",
      "490/490 [==============================] - 224s 457ms/step - loss: 1.3001 - fn: 12081.0000 - fp: 1832.0000 - tn: 123560.0000 - tp: 3593.0000 - precision: 0.6623 - recall: 0.2292 - val_loss: 1.1442 - val_fn: 2645.0000 - val_fp: 589.0000 - val_tn: 30763.0000 - val_tp: 1274.0000 - val_precision: 0.6838 - val_recall: 0.3251\n",
      "Epoch 27/100\n",
      "490/490 [==============================] - 1082s 2s/step - loss: 1.3018 - fn: 11992.0000 - fp: 1905.0000 - tn: 123487.0000 - tp: 3682.0000 - precision: 0.6590 - recall: 0.2349 - val_loss: 1.3586 - val_fn: 2878.0000 - val_fp: 589.0000 - val_tn: 30763.0000 - val_tp: 1041.0000 - val_precision: 0.6387 - val_recall: 0.2656\n",
      "Epoch 28/100\n",
      "490/490 [==============================] - 496s 1s/step - loss: 1.3176 - fn: 12045.0000 - fp: 1838.0000 - tn: 123554.0000 - tp: 3629.0000 - precision: 0.6638 - recall: 0.2315 - val_loss: 1.1548 - val_fn: 2643.0000 - val_fp: 648.0000 - val_tn: 30704.0000 - val_tp: 1276.0000 - val_precision: 0.6632 - val_recall: 0.3256\n",
      "Epoch 29/100\n",
      "490/490 [==============================] - 933s 2s/step - loss: 1.2973 - fn: 12015.0000 - fp: 1881.0000 - tn: 123511.0000 - tp: 3659.0000 - precision: 0.6605 - recall: 0.2334 - val_loss: 1.2014 - val_fn: 2765.0000 - val_fp: 573.0000 - val_tn: 30779.0000 - val_tp: 1154.0000 - val_precision: 0.6682 - val_recall: 0.2945\n",
      "Epoch 30/100\n",
      "490/490 [==============================] - 874s 2s/step - loss: 1.3012 - fn: 11984.0000 - fp: 1994.0000 - tn: 123398.0000 - tp: 3690.0000 - precision: 0.6492 - recall: 0.2354 - val_loss: 1.1077 - val_fn: 2483.0000 - val_fp: 728.0000 - val_tn: 30624.0000 - val_tp: 1436.0000 - val_precision: 0.6636 - val_recall: 0.3664\n",
      "Epoch 31/100\n",
      "490/490 [==============================] - 1405s 3s/step - loss: 1.2969 - fn: 11931.0000 - fp: 1896.0000 - tn: 123496.0000 - tp: 3743.0000 - precision: 0.6638 - recall: 0.2388 - val_loss: 1.1090 - val_fn: 2582.0000 - val_fp: 691.0000 - val_tn: 30661.0000 - val_tp: 1337.0000 - val_precision: 0.6593 - val_recall: 0.3412\n",
      "Epoch 32/100\n",
      "490/490 [==============================] - 117s 239ms/step - loss: 1.2875 - fn: 11878.0000 - fp: 2001.0000 - tn: 123391.0000 - tp: 3796.0000 - precision: 0.6548 - recall: 0.2422 - val_loss: 1.1228 - val_fn: 2527.0000 - val_fp: 760.0000 - val_tn: 30592.0000 - val_tp: 1392.0000 - val_precision: 0.6468 - val_recall: 0.3552\n",
      "Epoch 33/100\n",
      "490/490 [==============================] - 1450s 3s/step - loss: 1.2909 - fn: 11876.0000 - fp: 2028.0000 - tn: 123364.0000 - tp: 3798.0000 - precision: 0.6519 - recall: 0.2423 - val_loss: 1.2134 - val_fn: 2927.0000 - val_fp: 457.0000 - val_tn: 30895.0000 - val_tp: 992.0000 - val_precision: 0.6846 - val_recall: 0.2531\n",
      "Epoch 34/100\n",
      "490/490 [==============================] - 868s 2s/step - loss: 1.2745 - fn: 11862.0000 - fp: 2056.0000 - tn: 123336.0000 - tp: 3812.0000 - precision: 0.6496 - recall: 0.2432 - val_loss: 1.3200 - val_fn: 2803.0000 - val_fp: 641.0000 - val_tn: 30711.0000 - val_tp: 1116.0000 - val_precision: 0.6352 - val_recall: 0.2848\n",
      "Epoch 35/100\n",
      "490/490 [==============================] - 354s 724ms/step - loss: 1.2936 - fn: 11777.0000 - fp: 2102.0000 - tn: 123290.0000 - tp: 3897.0000 - precision: 0.6496 - recall: 0.2486 - val_loss: 1.1452 - val_fn: 2722.0000 - val_fp: 594.0000 - val_tn: 30758.0000 - val_tp: 1197.0000 - val_precision: 0.6683 - val_recall: 0.3054\n",
      "Epoch 36/100\n",
      "490/490 [==============================] - 469s 959ms/step - loss: 1.2847 - fn: 11763.0000 - fp: 2072.0000 - tn: 123320.0000 - tp: 3911.0000 - precision: 0.6537 - recall: 0.2495 - val_loss: 1.2698 - val_fn: 2877.0000 - val_fp: 548.0000 - val_tn: 30804.0000 - val_tp: 1042.0000 - val_precision: 0.6553 - val_recall: 0.2659\n",
      "Epoch 37/100\n",
      "490/490 [==============================] - 753s 2s/step - loss: 1.2700 - fn: 11726.0000 - fp: 2120.0000 - tn: 123272.0000 - tp: 3948.0000 - precision: 0.6506 - recall: 0.2519 - val_loss: 1.1711 - val_fn: 2711.0000 - val_fp: 627.0000 - val_tn: 30725.0000 - val_tp: 1208.0000 - val_precision: 0.6583 - val_recall: 0.3082\n",
      "Epoch 38/100\n",
      "490/490 [==============================] - 435s 889ms/step - loss: 1.2725 - fn: 11710.0000 - fp: 2165.0000 - tn: 123227.0000 - tp: 3964.0000 - precision: 0.6468 - recall: 0.2529 - val_loss: 1.1347 - val_fn: 2641.0000 - val_fp: 668.0000 - val_tn: 30684.0000 - val_tp: 1278.0000 - val_precision: 0.6567 - val_recall: 0.3261\n",
      "Epoch 39/100\n",
      "490/490 [==============================] - 584s 1s/step - loss: 1.2632 - fn: 11600.0000 - fp: 2090.0000 - tn: 123302.0000 - tp: 4074.0000 - precision: 0.6609 - recall: 0.2599 - val_loss: 1.1808 - val_fn: 2706.0000 - val_fp: 634.0000 - val_tn: 30718.0000 - val_tp: 1213.0000 - val_precision: 0.6567 - val_recall: 0.3095\n",
      "Epoch 40/100\n",
      "490/490 [==============================] - 498s 1s/step - loss: 1.2621 - fn: 11582.0000 - fp: 2142.0000 - tn: 123250.0000 - tp: 4092.0000 - precision: 0.6564 - recall: 0.2611 - val_loss: 1.1484 - val_fn: 2510.0000 - val_fp: 779.0000 - val_tn: 30573.0000 - val_tp: 1409.0000 - val_precision: 0.6440 - val_recall: 0.3595\n",
      "Epoch 41/100\n",
      "490/490 [==============================] - 88s 179ms/step - loss: 1.2726 - fn: 11675.0000 - fp: 2171.0000 - tn: 123221.0000 - tp: 3999.0000 - precision: 0.6481 - recall: 0.2551 - val_loss: 1.1620 - val_fn: 2784.0000 - val_fp: 577.0000 - val_tn: 30775.0000 - val_tp: 1135.0000 - val_precision: 0.6630 - val_recall: 0.2896\n",
      "Epoch 42/100\n",
      "490/490 [==============================] - 70s 143ms/step - loss: 1.2652 - fn: 11610.0000 - fp: 2188.0000 - tn: 123204.0000 - tp: 4064.0000 - precision: 0.6500 - recall: 0.2593 - val_loss: 1.1418 - val_fn: 2584.0000 - val_fp: 645.0000 - val_tn: 30707.0000 - val_tp: 1335.0000 - val_precision: 0.6742 - val_recall: 0.3406\n",
      "Epoch 43/100\n",
      "490/490 [==============================] - 71s 144ms/step - loss: 1.2469 - fn: 11578.0000 - fp: 2191.0000 - tn: 123201.0000 - tp: 4096.0000 - precision: 0.6515 - recall: 0.2613 - val_loss: 1.0846 - val_fn: 2516.0000 - val_fp: 669.0000 - val_tn: 30683.0000 - val_tp: 1403.0000 - val_precision: 0.6771 - val_recall: 0.3580\n",
      "Epoch 44/100\n",
      "490/490 [==============================] - 71s 145ms/step - loss: 1.2703 - fn: 11616.0000 - fp: 2254.0000 - tn: 123138.0000 - tp: 4058.0000 - precision: 0.6429 - recall: 0.2589 - val_loss: 1.2517 - val_fn: 2960.0000 - val_fp: 498.0000 - val_tn: 30854.0000 - val_tp: 959.0000 - val_precision: 0.6582 - val_recall: 0.2447\n",
      "Epoch 45/100\n",
      "490/490 [==============================] - 71s 145ms/step - loss: 1.2576 - fn: 11568.0000 - fp: 2171.0000 - tn: 123221.0000 - tp: 4106.0000 - precision: 0.6541 - recall: 0.2620 - val_loss: 1.2119 - val_fn: 2629.0000 - val_fp: 686.0000 - val_tn: 30666.0000 - val_tp: 1290.0000 - val_precision: 0.6528 - val_recall: 0.3292\n",
      "Epoch 46/100\n",
      "490/490 [==============================] - 73s 148ms/step - loss: 1.2537 - fn: 11624.0000 - fp: 2134.0000 - tn: 123258.0000 - tp: 4050.0000 - precision: 0.6549 - recall: 0.2584 - val_loss: 1.1270 - val_fn: 2532.0000 - val_fp: 705.0000 - val_tn: 30647.0000 - val_tp: 1387.0000 - val_precision: 0.6630 - val_recall: 0.3539\n",
      "Epoch 47/100\n",
      "490/490 [==============================] - 83s 169ms/step - loss: 1.2442 - fn: 11421.0000 - fp: 2218.0000 - tn: 123174.0000 - tp: 4253.0000 - precision: 0.6572 - recall: 0.2713 - val_loss: 1.1325 - val_fn: 2628.0000 - val_fp: 614.0000 - val_tn: 30738.0000 - val_tp: 1291.0000 - val_precision: 0.6777 - val_recall: 0.3294\n",
      "Epoch 48/100\n",
      "490/490 [==============================] - 89s 182ms/step - loss: 1.2477 - fn: 11521.0000 - fp: 2331.0000 - tn: 123061.0000 - tp: 4153.0000 - precision: 0.6405 - recall: 0.2650 - val_loss: 1.0845 - val_fn: 2582.0000 - val_fp: 629.0000 - val_tn: 30723.0000 - val_tp: 1337.0000 - val_precision: 0.6801 - val_recall: 0.3412\n",
      "Epoch 49/100\n",
      "490/490 [==============================] - 88s 179ms/step - loss: 1.2506 - fn: 11466.0000 - fp: 2244.0000 - tn: 123148.0000 - tp: 4208.0000 - precision: 0.6522 - recall: 0.2685 - val_loss: 1.1031 - val_fn: 2568.0000 - val_fp: 753.0000 - val_tn: 30599.0000 - val_tp: 1351.0000 - val_precision: 0.6421 - val_recall: 0.3447\n",
      "Epoch 50/100\n",
      "490/490 [==============================] - 89s 182ms/step - loss: 1.2432 - fn: 11473.0000 - fp: 2214.0000 - tn: 123178.0000 - tp: 4201.0000 - precision: 0.6549 - recall: 0.2680 - val_loss: 1.1494 - val_fn: 2601.0000 - val_fp: 676.0000 - val_tn: 30676.0000 - val_tp: 1318.0000 - val_precision: 0.6610 - val_recall: 0.3363\n",
      "Epoch 51/100\n",
      "490/490 [==============================] - 89s 181ms/step - loss: 1.2358 - fn: 11470.0000 - fp: 2242.0000 - tn: 123150.0000 - tp: 4204.0000 - precision: 0.6522 - recall: 0.2682 - val_loss: 1.0790 - val_fn: 2454.0000 - val_fp: 805.0000 - val_tn: 30547.0000 - val_tp: 1465.0000 - val_precision: 0.6454 - val_recall: 0.3738\n",
      "Epoch 52/100\n",
      "490/490 [==============================] - 89s 182ms/step - loss: 1.2451 - fn: 11436.0000 - fp: 2170.0000 - tn: 123222.0000 - tp: 4238.0000 - precision: 0.6614 - recall: 0.2704 - val_loss: 1.0566 - val_fn: 2287.0000 - val_fp: 886.0000 - val_tn: 30466.0000 - val_tp: 1632.0000 - val_precision: 0.6481 - val_recall: 0.4164\n",
      "Epoch 53/100\n",
      "490/490 [==============================] - 92s 188ms/step - loss: 1.2289 - fn: 11344.0000 - fp: 2296.0000 - tn: 123096.0000 - tp: 4330.0000 - precision: 0.6535 - recall: 0.2763 - val_loss: 1.1633 - val_fn: 2918.0000 - val_fp: 501.0000 - val_tn: 30851.0000 - val_tp: 1001.0000 - val_precision: 0.6664 - val_recall: 0.2554\n",
      "Epoch 54/100\n",
      "490/490 [==============================] - 264s 539ms/step - loss: 1.2435 - fn: 11469.0000 - fp: 2267.0000 - tn: 123125.0000 - tp: 4205.0000 - precision: 0.6497 - recall: 0.2683 - val_loss: 1.0418 - val_fn: 2363.0000 - val_fp: 702.0000 - val_tn: 30650.0000 - val_tp: 1556.0000 - val_precision: 0.6891 - val_recall: 0.3970\n",
      "Epoch 55/100\n",
      "490/490 [==============================] - 123s 250ms/step - loss: 1.2436 - fn: 11370.0000 - fp: 2280.0000 - tn: 123112.0000 - tp: 4304.0000 - precision: 0.6537 - recall: 0.2746 - val_loss: 1.1109 - val_fn: 2522.0000 - val_fp: 782.0000 - val_tn: 30570.0000 - val_tp: 1397.0000 - val_precision: 0.6411 - val_recall: 0.3565\n",
      "Epoch 56/100\n",
      "490/490 [==============================] - 105s 215ms/step - loss: 1.2360 - fn: 11364.0000 - fp: 2145.0000 - tn: 123247.0000 - tp: 4310.0000 - precision: 0.6677 - recall: 0.2750 - val_loss: 1.3918 - val_fn: 3081.0000 - val_fp: 548.0000 - val_tn: 30804.0000 - val_tp: 838.0000 - val_precision: 0.6046 - val_recall: 0.2138\n",
      "Epoch 57/100\n",
      "490/490 [==============================] - 86s 175ms/step - loss: 1.2403 - fn: 11421.0000 - fp: 2275.0000 - tn: 123117.0000 - tp: 4253.0000 - precision: 0.6515 - recall: 0.2713 - val_loss: 1.0601 - val_fn: 2397.0000 - val_fp: 725.0000 - val_tn: 30627.0000 - val_tp: 1522.0000 - val_precision: 0.6773 - val_recall: 0.3884\n",
      "Epoch 58/100\n",
      "490/490 [==============================] - 75s 154ms/step - loss: 1.2331 - fn: 11313.0000 - fp: 2265.0000 - tn: 123127.0000 - tp: 4361.0000 - precision: 0.6582 - recall: 0.2782 - val_loss: 1.2040 - val_fn: 2894.0000 - val_fp: 466.0000 - val_tn: 30886.0000 - val_tp: 1025.0000 - val_precision: 0.6875 - val_recall: 0.2615\n",
      "Epoch 59/100\n",
      "490/490 [==============================] - 107s 218ms/step - loss: 1.2308 - fn: 11397.0000 - fp: 2252.0000 - tn: 123140.0000 - tp: 4277.0000 - precision: 0.6551 - recall: 0.2729 - val_loss: 1.1060 - val_fn: 2436.0000 - val_fp: 812.0000 - val_tn: 30540.0000 - val_tp: 1483.0000 - val_precision: 0.6462 - val_recall: 0.3784\n",
      "Epoch 60/100\n",
      "255/490 [==============>...............] - ETA: 43s - loss: 1.2402 - fn: 5943.0000 - fp: 1210.0000 - tn: 64022.0000 - tp: 2211.0000 - precision: 0.6463 - recall: 0.2712"
     ]
    }
   ],
   "source": [
    "# steps_per_epoch: number of batches to be drawn from the generator after assuming epoch over\n",
    "# epochs: number of epochs\n",
    "# validation_steps: how many batches to draw from the validation generator for evaluation\n",
    "\n",
    "# TODO: set to the number of images we have\n",
    "number_training = tot_images # TODO: contare elementi training cartella\n",
    "number_eval = n_images_eval\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=int(math.ceil((1. * number_training) / batch_size)),\n",
    "      epochs=epochs,\n",
    "      class_weight=weights,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=int(math.ceil((1. * number_eval) / batch_size)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation ACC')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# smooth curves if they look noisy\n",
    "# replace each point with an exponential moving average of the previous points\n",
    "def smooth_curve(points, factor=0.8):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs,\n",
    "         smooth_curve(acc), 'r', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), 'r', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# display average, the model may improve even if not reflected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Early stopping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "\n",
    "callbacks_list = [\n",
    "        # interrupts training when accuracy has stopped improving accuracy on the validation set for at least 3+1=4 epochs\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='acc', # should be part of the metrics specific during compilation\n",
    "            patience=10,\n",
    "        ),\n",
    "        # save the current weights after every epoch\n",
    "        #keras.callbacks.ModelCheckpoint(\n",
    "        #    filepath=os.path.join(paths['MODELS'],'CNN_baseline.h5'),\n",
    "        #    monitor='val_loss', # do not overwrite until val_loss is improved\n",
    "        #    save_best_only=True\n",
    "        #),\n",
    "        # monitor the model's validation loss and reduce the LR when the validation loss has stopped improving, effective strategy to escape local minima\n",
    "        #keras.callbacks.ReduceLROnPlateau(\n",
    "        #    monitor='val_loss',\n",
    "        #    factor=0.2, # divides LR by 5 when triggered\n",
    "        #    patience=3 # called when stopped improving for 3 epochs\n",
    "        #),\n",
    "        #keras.callbacks.TensorBoard(\n",
    "        #    log_dir=paths['LOG_DIR'],\n",
    "        #    write_graph=True,\n",
    "        #    histogram_freq=1 # record activation histograms every 1 epoch\n",
    "        #)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=int(math.ceil((1. * number_training) / batch_size)),\n",
    "      epochs=epochs,\n",
    "      validation_data=validation_generator,\n",
    "      callbacks=callbacks_list,\n",
    "      validation_steps=int(math.ceil((1. * number_eval) / batch_size)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Model testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dir=paths[\"TEST_PATH\"]\n",
    "test_datagen = ImageDataGenerator(rescale=rescale_size) # it should not be augmented\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "# if performances are much wors than validation ones, during hyperparameter optimization (when done) the process has overfitted the validdation set, if so go to a more clear protocol such as Kfold CV\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=2)\n",
    "print('test acc:', test_acc)\n",
    "print('test loss:', test_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: is it balanced? If not consider ROC AUC for example, FPR, TPR, and others"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. Model exportation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"models/CNN_baseline_class_weights.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9. Plot model as graph of layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file='model.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}