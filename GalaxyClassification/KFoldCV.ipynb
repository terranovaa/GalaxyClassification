{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 16:19:16.756244: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'TRAIN_PATH' : os.path.join('workspace', 'images', 'train'),\n",
    "    'TEST_PATH' : os.path.join('workspace', 'images','test'),\n",
    "    'EVAL_PATH' : os.path.join('workspace', 'images','eval'),\n",
    "    'IMAGES_PATH': os.path.join('workspace','images','all'),\n",
    "    'ANNOTATION_PATH': os.path.join('workspace','annotations'),\n",
    "    'RESULTS_PATH': os.path.join('workspace','results')\n",
    " }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "input_height = 69\n",
    "input_width = 69\n",
    "batch_size = 4\n",
    "\n",
    "augmentation=True\n",
    "# TODO: find best ones using the display_data_augmentation_sample jupyter notebook\n",
    "rescale_size=1./255\n",
    "rotation_range=20 # range within which we randomly rotate pictures\n",
    "width_shift_range=0.05 # range withing which we shift image horizontally\n",
    "height_shift_range=0.05 # range withing which we shift image vertically\n",
    "shear_range=0.2 # random shearing transformation\n",
    "zoom_range=0.2 # random zoom inside pictures\n",
    "horizontal_flip=True\n",
    "fill_mode='nearest' # strategy to fill newly created pixels after rotation or shift\n",
    "# consider also stride (>1), type of pooling (Max, Avg), padding (same, valid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "K = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"models\",\"CNN_baseline.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "epochs = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def emptyFolders():\n",
    "    for i in range(0,10):\n",
    "        for file in os.listdir(os.path.join(paths[\"TRAIN_PATH\"],str(i))):\n",
    "            if file != \".DS_Store\":\n",
    "                os.remove(os.path.join(paths[\"TRAIN_PATH\"],str(i), file))\n",
    "        for file in os.listdir(os.path.join(paths[\"TEST_PATH\"],str(i))):\n",
    "            if file != \".DS_Store\":\n",
    "                os.remove(os.path.join(paths[\"TEST_PATH\"],str(i), file))\n",
    "\n",
    "df = pd.read_csv(os.path.join(paths['ANNOTATION_PATH'],\"annotations.csv\"))\n",
    "df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== K-Fold CV Iteration: 1/10 =======\n",
      "Folders empty..\n",
      "Train:  19606\n",
      "Test:  2179\n",
      "Found 19606 images belonging to 10 classes.\n",
      "Found 2179 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/fbpz2wyx1kb4b5zgt8w_tsp40000gn/T/ipykernel_10940/1823151045.py:62: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.8372 - accuracy: 0.2500 - val_loss: 1.4466 - val_accuracy: 0.5000\n",
      "====== K-Fold CV Iteration: 2/10 =======\n",
      "Folders empty..\n",
      "Train:  19606\n",
      "Test:  2179\n",
      "Found 19606 images belonging to 10 classes.\n",
      "Found 2179 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/fbpz2wyx1kb4b5zgt8w_tsp40000gn/T/ipykernel_10940/1823151045.py:62: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 2.3123 - accuracy: 0.2500 - val_loss: 1.5969 - val_accuracy: 0.5000\n",
      "====== K-Fold CV Iteration: 3/10 =======\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_index, test_index \u001B[38;5;129;01min\u001B[39;00m kf\u001B[38;5;241m.\u001B[39msplit(df_new):\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m====== K-Fold CV Iteration: \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m =======\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (i,K))\n\u001B[0;32m---> 18\u001B[0m     \u001B[43memptyFolders\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFolders empty..\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(train_index))\n",
      "Cell \u001B[0;32mIn[20], line 8\u001B[0m, in \u001B[0;36memptyFolders\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(paths[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTEST_PATH\u001B[39m\u001B[38;5;124m\"\u001B[39m],\u001B[38;5;28mstr\u001B[39m(i))):\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.DS_Store\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m----> 8\u001B[0m         \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremove\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpaths\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTEST_PATH\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "## Training with K-fold cross validation\n",
    "kf = KFold(n_splits=K, random_state=None, shuffle=True)\n",
    "kf.get_n_splits(df)\n",
    "\n",
    "# TODO: change adapting to our project\n",
    "df_new = pd.DataFrame()\n",
    "for _, row in df.iterrows():\n",
    "    if(row['Path'].endswith(\".jpg\")):\n",
    "        new_row = { 'Path': row['Path'], 'Class': row['Class'] }\n",
    "        df_new_row = pd.DataFrame([new_row])\n",
    "        df_new = pd.concat([df_new, df_new_row],ignore_index=True)\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "time.sleep(5)\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(df_new):\n",
    "    print(\"====== K-Fold CV Iteration: %d/%d =======\" % (i,K))\n",
    "    emptyFolders()\n",
    "    print(\"Folders empty..\")\n",
    "\n",
    "    print(\"Train: \", len(train_index))\n",
    "    print(\"Test: \", len(test_index))\n",
    "\n",
    "    df_train = df_new.iloc[train_index]\n",
    "    df_test = df_new.iloc[test_index]\n",
    "\n",
    "    for _, row in df_train.iterrows():\n",
    "        shutil.copy(os.path.join(paths[\"IMAGES_PATH\"],row['Path']),\n",
    "                os.path.join(paths[\"TRAIN_PATH\"],str(row['Class']),row['Path']))\n",
    "    for _, row in df_test.iterrows():\n",
    "        shutil.copy(os.path.join(paths[\"IMAGES_PATH\"],row['Path']),\n",
    "                os.path.join(paths[\"TEST_PATH\"],str(row['Class']),row['Path']))\n",
    "\n",
    "    if augmentation:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "          rescale=rescale_size,\n",
    "          rotation_range=rotation_range,\n",
    "          width_shift_range=width_shift_range,\n",
    "          height_shift_range=height_shift_range,\n",
    "          shear_range=shear_range,\n",
    "          zoom_range=zoom_range,\n",
    "          horizontal_flip=horizontal_flip,\n",
    "          fill_mode=fill_mode)\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_dir=paths['TRAIN_PATH']\n",
    "    # TODO: Consider if the output should be normalized\n",
    "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "    # validation set image data generator\n",
    "    val_datagen = ImageDataGenerator(rescale=rescale_size) # it should not be augmented\n",
    "    validation_dir=paths['TEST_PATH']\n",
    "    validation_generator = val_datagen.flow_from_directory(validation_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "    try:\n",
    "        model = load_model(model_path, compile=True)\n",
    "    except Exception as OSError:\n",
    "        pass\n",
    "\n",
    "    # set steps, epochs, etc.\n",
    "    history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=1,#int(math.ceil((1. * len(df_train)) / batch_size)),\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=1)#int(math.ceil((1. * len(df_test)) / batch_size)))\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        new_row = { 'k': i, 'epoch': epoch+1, 'acc': acc[epoch], 'val_acc': val_acc[epoch], 'loss': loss[epoch], 'val_loss': val_loss[epoch] }\n",
    "        df_new_row = pd.DataFrame([new_row])\n",
    "        df_results = pd.concat([df_results, df_new_row],ignore_index=True)\n",
    "\n",
    "    model.save(model_path)\n",
    "    i+=1\n",
    "\n",
    "print(df_results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df_results.to_csv(os.path.join(paths['RESULTS_PATH'], \"resultsKFold.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
