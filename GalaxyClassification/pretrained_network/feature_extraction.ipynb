{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras.optimizers as optimizers\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# image parameters\n",
    "input_height = 69\n",
    "input_width = 69\n",
    "\n",
    "# augmentation parameters\n",
    "rescale = True\n",
    "if rescale:\n",
    "    rescale_size=1./255\n",
    "else:\n",
    "    rescale_size=1\n",
    "augmentation=False\n",
    "\n",
    "rotation_range=40\n",
    "width_shift_range=0.2\n",
    "height_shift_range=0.1\n",
    "shear_range=0.2\n",
    "zoom_range=0.2\n",
    "horizontal_flip=True\n",
    "fill_mode='nearest'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# best loss function for multi-class classification, measures the distance between two probability distributions\n",
    "# the probability distribution of the output of the network and the true distribution of the labels\n",
    "loss_function='categorical_crossentropy'\n",
    "\n",
    "optimizer='rmsprop'\n",
    "optimizer_learning_rate=1e-4\n",
    "epochs=100\n",
    "batch_size=32\n",
    "num_classes = 9\n",
    "regularizer=regularizers.l1_l2(l1=0.001, l2=0.001) # simultaneous l1 and l2, add 0.001*weight_coefficient_value + 0.001 * 1/2*weight^2\n",
    "\n",
    "if optimizer == 'rmsprop':\n",
    "    optimizer=optimizers.RMSprop(learning_rate=optimizer_learning_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# customized metrics for multi class classification\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "metrics = [\n",
    "    precision,\n",
    "    recall,\n",
    "    tf.keras.metrics.CategoricalAccuracy(name='acc')\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'TRAIN_PATH' : os.path.join('..','workspace', 'images', 'train'),\n",
    "    'TEST_PATH' : os.path.join('..','workspace', 'images','test'),\n",
    "    'EVAL_PATH' : os.path.join('..','workspace', 'images','eval'),\n",
    "    'IMAGES_PATH': os.path.join('..','workspace','images','all'),\n",
    "    'LOG_DIR' : os.path.join('..','model', 'log_dir')\n",
    " }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training set class distribution\n",
    "def plotTrainingDistribution():\n",
    "    files_per_label = dict()\n",
    "    for i in range(9):\n",
    "      path = os.path.join(paths['TRAIN_PATH'],str(i))\n",
    "      n_images = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
    "      files_per_label[i] = n_images\n",
    "    plt.bar(list(files_per_label.keys()), files_per_label.values(), color='g')\n",
    "    plt.show()\n",
    "    print(files_per_label)\n",
    "    return files_per_label\n",
    "\n",
    "files_per_label = plotTrainingDistribution()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# class weights computation\n",
    "tot_images = sum(list(files_per_label.values()))\n",
    "weights = dict([ (class_label , tot_images/(num_classes * n_images)) for class_label, n_images in files_per_label.items()])\n",
    "print(weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training set image data generator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_dir=paths['TRAIN_PATH']\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# validation set image data generator\n",
    "val_datagen = ImageDataGenerator(rescale=rescale_size)\n",
    "validation_dir=paths['EVAL_PATH']\n",
    "validation_generator = val_datagen.flow_from_directory(validation_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Model creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "# pre-trained model on which we applied feature extraction\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                    include_top=False, # exclude fully connected layer\n",
    "                    input_shape=(input_width, input_height, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model(input_conv_base):\n",
    "    #build the cnn using the pre-trained cnn\n",
    "    built_model = models.Sequential()\n",
    "    built_model.add(input_conv_base)\n",
    "    # add fully connected layer\n",
    "    built_model.add(Flatten())\n",
    "    built_model.add(Dense(64, activation='relu'))\n",
    "    built_model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "    return built_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_base.trainable = False # freeze conv_base otherwise representation previously learned got updated\n",
    "# only the weights of the densely connected layer will be trained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#build model\n",
    "model = build_model(conv_base)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_training = tot_images\n",
    "\n",
    "n_images_eval = 0\n",
    "for i in range(9):\n",
    "    path = os.path.join(paths['EVAL_PATH'],str(i))\n",
    "    # compute number of images in each eval folder and sum it up\n",
    "    n_images_eval = n_images_eval + len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n",
    "\n",
    "number_eval = n_images_eval"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "callbacks_list = [\n",
    "        # interrupts training when accuracy has stopped improving accuracy on the validation set for at least 3+1=4 epochs\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='acc', # should be part of the metrics specific during compilation\n",
    "            patience=5,\n",
    "        ),\n",
    "        # monitor the model's validation loss and reduce the LR when the validation loss has stopped improving, effective strategy to escape local minima\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2, # divides LR by 5 when triggered\n",
    "            patience=3 # called when stopped improving for 3 epochs\n",
    "        )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=int(math.ceil((1. * number_training) / batch_size)),\n",
    "      epochs=epochs,\n",
    "      class_weight=weights,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=int(math.ceil((1. * number_eval) / batch_size)),\n",
    "      callbacks=callbacks_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "  # 5. Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation ACC')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "plt.plot(epochs, precision, 'r', label='Training precision')\n",
    "plt.plot(epochs, val_precision, 'b', label='Validation precision')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "plt.plot(epochs, recall, 'r', label='Training recall')\n",
    "plt.plot(epochs, val_recall, 'b', label='Validation recall')\n",
    "plt.title('Training and validation Recall')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# smooth curves if they look noisy\n",
    "# replace each point with an exponential moving average of the previous points\n",
    "def smooth_curve(points, factor=0.8):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs,\n",
    "         smooth_curve(acc), 'r', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), 'r', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# display average, the model may improve even if not reflected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "  # 6. Model testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_test = 0\n",
    "for i in range(9):\n",
    "      path = os.path.join(paths['TEST_PATH'],str(i))\n",
    "      n_images = len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n",
    "      number_test += n_images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dir=paths['TEST_PATH']\n",
    "test_datagen = ImageDataGenerator(rescale=rescale_size) # it should not be augmented\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical', classes=None, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# classification report and confusion matrixx\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "test_generator.reset()\n",
    "Y_pred = model.predict_generator(test_generator, number_test // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['0','1','2','3','4','5','6','7','8']\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ROC curve and AUC\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "\n",
    "    for (idx, c_label) in enumerate(target_names):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
    "    c_ax.legend()\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "test_generator.reset()\n",
    "y_pred = model.predict_generator(test_generator, verbose = True)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(\"Multiclass roc auc score:\", multiclass_roc_auc_score(test_generator.classes, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Model exportation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"models/VGG_ feature_extractor.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. Plot model as graph of layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file='feature_extraction_model.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
