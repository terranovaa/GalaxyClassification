{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TO BE ADAPTED"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scipy.stats import ranksums"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"workspace\", \"model_results\", \"data.csv\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Paired t-test or other"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_iterations = 10\n",
    "models = df.model.unique()\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "TrainACC = []\n",
    "ACC = []\n",
    "Prec = []\n",
    "Recall = []\n",
    "for model in models:\n",
    "    ACCinner = []\n",
    "    Precinner = []\n",
    "    Recallinner = []\n",
    "    TrainACCinner = []\n",
    "    for iteration in range(0,max_iterations):\n",
    "        new_df = df.loc[(df['iteration'] == iteration) & (df['model'] == model)]\n",
    "        if not new_df.empty:\n",
    "            TrainACCinner.append(new_df['acc'].iloc[0])\n",
    "            ACCinner.append(new_df['test_acc'].iloc[0])\n",
    "            Precinner.append(new_df['test_prec'].iloc[0])\n",
    "            Recallinner.append(new_df['test_recall'].iloc[0])\n",
    "    ACC.append(ACCinner)\n",
    "    Prec.append(Precinner)\n",
    "    Recall.append(Recallinner)\n",
    "    TrainACC.append(TrainACCinner)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confidence_level = 0.05\n",
    "number_of_algorithms = 4\n",
    "\n",
    "print(\"Indexes of the algorithms that do not reject the null hypothesis with confidence level \"+str(confidence_level)+\":\")\n",
    "\n",
    "for i in range(0,number_of_algorithms):\n",
    "    for j in range(0,number_of_algorithms):\n",
    "        if i != j:\n",
    "            if(ranksums(ACC[i], ACC[j]).pvalue >= confidence_level):\n",
    "                print(\"ACC\",i,j)\n",
    "            if(ranksums(TrainACC[i], TrainACC[j]).pvalue >= confidence_level):\n",
    "                print(\"ACC\",i,j)\n",
    "            if(ranksums(Prec[i], Prec[j]).pvalue >= confidence_level):\n",
    "                print(\"Prec\",i,j)\n",
    "            if(ranksums(Recall[i], Recall[j]).pvalue >= confidence_level):\n",
    "                print(\"Recall\",i,j)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
