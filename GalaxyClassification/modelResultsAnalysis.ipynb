{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scipy.stats import ranksums"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Wilcoxon signed rank sum test for K-Fold Precision and Recall Check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"workspace\", \"results\", \"resultsKFold.csv\"))\n",
    "max_iterations = 5\n",
    "models = df.model.unique()\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "Prec = []\n",
    "Recall = []\n",
    "Acc = []\n",
    "for model in models:\n",
    "    Recallinner = []\n",
    "    Precinner = []\n",
    "    Accinner = []\n",
    "    for iteration in range(0,max_iterations):\n",
    "        new_df = df.loc[(df['k'] == iteration) & (df['model'] == model)]\n",
    "        if not new_df.empty:\n",
    "            Precinner.append(new_df['test_precision'].iloc[0])\n",
    "            Recallinner.append(new_df['test_recall'].iloc[0])\n",
    "            Accinner.append(new_df['test_acc'].iloc[0])\n",
    "    Prec.append(Precinner)\n",
    "    Recall.append(Recallinner)\n",
    "    Acc.append(Accinner)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.8001208367347717,\n  0.7980845236778259,\n  0.7767937564849854,\n  0.8051113963127136],\n [0.7587367987632752,\n  0.7629765868186951,\n  0.7940009427070618,\n  0.7664759659767151]]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  1 0 0.020921335337794014\n",
      "Recall  1 0 0.043308142810791955\n",
      "Accuracy  1 0 0.043308142810791955\n"
     ]
    }
   ],
   "source": [
    "confidence_level = 0.05\n",
    "number_of_algorithms = 2\n",
    "\n",
    "for i in range(0,number_of_algorithms):\n",
    "    for j in range(0,i):\n",
    "        if i != j:\n",
    "            print(\"Precision \",i,j,ranksums(Prec[i], Prec[j]).pvalue)\n",
    "            if(ranksums(Prec[i], Prec[j]).pvalue >= confidence_level):\n",
    "                print(\"Above confidence level\")\n",
    "            print(\"Recall \",i,j,ranksums(Recall[i], Recall[j]).pvalue)\n",
    "            if(ranksums(Recall[i], Recall[j]).pvalue >= confidence_level):\n",
    "                print(\"Above confidence level\")\n",
    "            print(\"Accuracy \",i,j,ranksums(Acc[i], Acc[j]).pvalue)\n",
    "            if(ranksums(Acc[i], Acc[j]).pvalue >= confidence_level):\n",
    "                print(\"Above confidence level\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Metrics calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch model\n",
      "Acc: 0.7950276283025741 0.012509221134981624\n",
      "Precision: 0.8179235428571701 0.015698771425719932\n",
      "Recall: 0.7003897792816163 0.017431411928132873\n",
      "VGG model\n",
      "Acc: 0.7705475735664368 0.015952562533927257\n",
      "Precision: 0.79042187333107 0.010205420775277222\n",
      "Recall: 0.7360397559213637 0.01660183131212313\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Scratch model\")\n",
    "print(\"Acc:\",statistics.mean(Acc[0]),statistics.stdev(Acc[0]))\n",
    "print(\"Precision:\",statistics.mean(Prec[0]),statistics.stdev(Prec[0]))\n",
    "print(\"Recall:\",statistics.mean(Recall[0]),statistics.stdev(Recall[0]))\n",
    "print(\"VGG model\")\n",
    "print(\"Acc:\",statistics.mean(Acc[1]),statistics.stdev(Acc[1]))\n",
    "print(\"Precision:\",statistics.mean(Prec[1]),statistics.stdev(Prec[1]))\n",
    "print(\"Recall:\",statistics.mean(Recall[1]),statistics.stdev(Recall[1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
