{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. TO UPDATE Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/francoterranova/lib/python3.9/site-packages (3.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/francoterranova/lib/python3.9/site-packages (from matplotlib) (1.22.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/francoterranova/lib/python3.9/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/francoterranova/lib/python3.9/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/francoterranova/lib/python3.9/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/francoterranova/lib/python3.9/site-packages (from matplotlib) (2.4.7)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/francoterranova/lib/python3.9/site-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 13:17:44.452174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.optimizers as optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this jupyter notebook contains the code used to analyze the baseline approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# image parameters\n",
    "input_height = 69\n",
    "input_width = 69\n",
    "\n",
    "# augmentation parameters\n",
    "rescale = True\n",
    "if rescale:\n",
    "    rescale_size=1./255\n",
    "else:\n",
    "    rescale_size=1\n",
    "augmentation=False\n",
    "\n",
    "rotation_range=40\n",
    "width_shift_range=0.2\n",
    "height_shift_range=0.1\n",
    "shear_range=0.2\n",
    "zoom_range=0.2\n",
    "horizontal_flip=True\n",
    "fill_mode='nearest'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# best loss function for multi-class classification, measures the distance between two probability distributions\n",
    "# the probability distribution of the output of the network and the true distribution of the labels\n",
    "loss_function='categorical_crossentropy'\n",
    "\n",
    "optimizer='rmsprop'\n",
    "optimizer_learning_rate=1e-4\n",
    "epochs=100\n",
    "batch_size=32\n",
    "num_classes = 9\n",
    "regularizer=regularizers.l1_l2(l1=0.001, l2=0.001) # simultaneous l1 and l2, add 0.001*weight_coefficient_value + 0.001 * 1/2*weight^2\n",
    "\n",
    "if optimizer == 'rmsprop':\n",
    "    optimizer=optimizers.RMSprop(learning_rate=optimizer_learning_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# customized metrics for multi class classification\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "# best loss function for multi-class classification, measures the distance between two probability distributions\n",
    "# the probability distribution of the output of the network and the true distribution of the labels\n",
    "loss_function='categorical_crossentropy'\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "metrics = [\n",
    "    precision,\n",
    "    recall,\n",
    "    tf.keras.metrics.CategoricalAccuracy(name='acc')\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Holdout method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'TRAIN_PATH' : os.path.join('workspace', 'images', 'train'),\n",
    "    'TEST_PATH' : os.path.join('workspace', 'images','test'),\n",
    "    'EVAL_PATH' : os.path.join('workspace', 'images','eval'),\n",
    "    'IMAGES_PATH': os.path.join('workspace','images','all'),\n",
    "    'ANNOTATION_PATH': os.path.join('workspace','annotations'),\n",
    "    'LOG_DIR' : os.path.join('model', 'log_dir')\n",
    " }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# create paths\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'workspace/images/train/9'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# remove all files already present for an old holdout method execution\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpaths\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTRAIN_PATH\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m      4\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.DS_Store\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m      5\u001B[0m             os\u001B[38;5;241m.\u001B[39mremove(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(paths[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTRAIN_PATH\u001B[39m\u001B[38;5;124m\"\u001B[39m],\u001B[38;5;28mstr\u001B[39m(i), file))\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'workspace/images/train/9'"
     ]
    }
   ],
   "source": [
    "# remove all files already present for an old holdout method execution\n",
    "for i in range(0,10):\n",
    "    for file in os.listdir(os.path.join(paths[\"TRAIN_PATH\"],str(i))):\n",
    "        if file != \".DS_Store\":\n",
    "            os.remove(os.path.join(paths[\"TRAIN_PATH\"],str(i), file))\n",
    "    for file in os.listdir(os.path.join(paths[\"TEST_PATH\"],str(i))):\n",
    "        if file != \".DS_Store\":\n",
    "            os.remove(os.path.join(paths[\"TEST_PATH\"],str(i), file))\n",
    "    for file in os.listdir(os.path.join(paths[\"EVAL_PATH\"],str(i))):\n",
    "        if file != \".DS_Store\":\n",
    "            os.remove(os.path.join(paths[\"EVAL_PATH\"],str(i), file))\n",
    "\n",
    "df = pd.read_csv(os.path.join(paths['ANNOTATION_PATH'],\"annotations.csv\"))\n",
    "df = df.dropna()\n",
    "\n",
    "for i in range(0,10):\n",
    "    if not os.path.exists(os.path.join(paths[\"EVAL_PATH\"],str(i))):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {os.path.join(paths[\"EVAL_PATH\"],str(i))}\n",
    "    if not os.path.exists(os.path.join(paths[\"TRAIN_PATH\"],str(i))):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {os.path.join(paths[\"TRAIN_PATH\"],str(i))}\n",
    "    if not os.path.exists(os.path.join(paths[\"TEST_PATH\"],str(i))):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {os.path.join(paths[\"TEST_PATH\"],str(i))}\n",
    "\n",
    "# split in training set (90%) and test set (10%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df, test_size=0.1, shuffle=True)\n",
    "print(\"Train size: \" + str(len(X_train)))\n",
    "\n",
    "for index, row in X_test.iterrows():\n",
    "    shutil.copy(os.path.join(paths[\"IMAGES_PATH\"],str(row['Path'])),\n",
    "                os.path.join(paths[\"TEST_PATH\"],str(row['Class']),str(row['Path'])))\n",
    "\n",
    "# split the training set into the final training set (80%) and validation set (20%)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "print(\"Test size: \" + str(len(X_test)))\n",
    "print(\"Eval size: \" + str(len(X_eval)))\n",
    "\n",
    "for index, row in X_train.iterrows():\n",
    "    shutil.copy(os.path.join(paths[\"IMAGES_PATH\"],str(row['Path'])),\n",
    "                os.path.join(paths[\"TRAIN_PATH\"],str(row['Class']),str(row['Path'])))\n",
    "\n",
    "for _, row in X_eval.iterrows():\n",
    "    shutil.copy(os.path.join(paths[\"IMAGES_PATH\"],str(row['Path'])),\n",
    "                os.path.join(paths[\"EVAL_PATH\"],str(row['Class']),str(row['Path'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training set image data generator\n",
    "if augmentation:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "          rescale=rescale_size,\n",
    "          rotation_range=rotation_range,\n",
    "          width_shift_range=width_shift_range,\n",
    "          height_shift_range=height_shift_range,\n",
    "          shear_range=shear_range,\n",
    "          zoom_range=zoom_range,\n",
    "          horizontal_flip=horizontal_flip,\n",
    "          fill_mode=fill_mode)\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir=paths['TRAIN_PATH']\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# validation set image data generator\n",
    "val_datagen = ImageDataGenerator(rescale=rescale_size) # it should not be augmented\n",
    "\n",
    "validation_dir=paths['EVAL_PATH']\n",
    "validation_generator = val_datagen.flow_from_directory(validation_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Model creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function used to create the CNN structure used for the classification\n",
    "def create_cnn(width, height, depth, num_classes,filters=(16, 32, 64)):\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    model = models.Sequential()\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # first CONV layer set appropriately\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(f, (3, 3), activation=\"relu\", padding=\"same\", kernel_regularizer=regularizer, input_shape=inputShape))\n",
    "        else:\n",
    "            model.add(Conv2D(f, (3, 3), activation=\"relu\", padding=\"same\", kernel_regularizer=regularizer))\n",
    "        # with padding = same we are able to center convolutional windows around every input tile, in order to have always the same size of the input image\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # FLATTEN => FC => RELU => BN => DROPOUT\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = create_cnn(input_width, input_height, 3, 10, (8,16))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# steps_per_epoch: number of batches to be drawn from the generator after assuming epoch over\n",
    "# epochs: number of epochs\n",
    "# validation_steps: how many batches to draw from the validation generator for evaluation\n",
    "\n",
    "number_training = len(X_train)\n",
    "number_eval = len(X_eval)\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=int(math.ceil((1. * number_training) / batch_size)),\n",
    "      epochs=epochs,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=int(math.ceil((1. * number_eval) / batch_size)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation ACC')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "plt.plot(epochs, precision, 'r', label='Training precision')\n",
    "plt.plot(epochs, val_precision, 'b', label='Validation precision')\n",
    "plt.title('Training and validation Precision')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "plt.plot(epochs, recall, 'r', label='Training recall')\n",
    "plt.plot(epochs, val_recall, 'b', label='Validation recall')\n",
    "plt.title('Training and validation Recall')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# smooth curves if they look noisy\n",
    "# replace each point with an exponential moving average of the previous points\n",
    "def smooth_curve(points, factor=0.8):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs,\n",
    "         smooth_curve(acc), 'r', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.legend()\n",
    "plt.figure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), 'r', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# display average, the model may improve even if not reflected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Early stopping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "\n",
    "callbacks_list = [\n",
    "        # interrupts training when accuracy has stopped improving accuracy on the validation set for at least 3+1=4 epochs\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='acc', # should be part of the metrics specific during compilation\n",
    "            patience=3,\n",
    "        ),\n",
    "        # save the current weights after every epoch\n",
    "        #keras.callbacks.ModelCheckpoint(\n",
    "        #    filepath=os.path.join(paths['MODELS'],'CNN_baseline.h5'),\n",
    "        #    monitor='val_loss', # do not overwrite until val_loss is improved\n",
    "        #    save_best_only=True\n",
    "        #),\n",
    "        # monitor the model's validation loss and reduce the LR when the validation loss has stopped improving, effective strategy to escape local minima\n",
    "        #keras.callbacks.ReduceLROnPlateau(\n",
    "        #    monitor='val_loss',\n",
    "        #    factor=0.2, # divides LR by 5 when triggered\n",
    "        #    patience=3 # called when stopped improving for 3 epochs\n",
    "        #),\n",
    "        #keras.callbacks.TensorBoard(\n",
    "        #    log_dir=paths['LOG_DIR'],\n",
    "        #    write_graph=True,\n",
    "        #    histogram_freq=1 # record activation histograms every 1 epoch\n",
    "        #)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=int(math.ceil((1. * number_training) / batch_size)),\n",
    "      epochs=200,\n",
    "      validation_data=validation_generator,\n",
    "      callbacks=callbacks_list,\n",
    "      validation_steps=int(math.ceil((1. * number_eval) / batch_size)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Model testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_test = 0\n",
    "for i in range(9):\n",
    "      path = os.path.join(paths['TEST_PATH'],str(i))\n",
    "      n_images = len([f for f in os.listdir(path)if os.path.isfile(os.path.join(path, f))])\n",
    "      number_test += n_images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test set image generator\n",
    "test_dir=paths['TEST_PATH']\n",
    "test_datagen = ImageDataGenerator(rescale=rescale_size) # it should not be augmented\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(input_width, input_height), batch_size=batch_size, class_mode='categorical', classes=None, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# confusion matrix and classification report\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "test_generator.reset()\n",
    "Y_pred = model.predict_generator(test_generator, number_test // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['0','1','2','3','4','5','6','7','8']\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ROC curve and AUC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "\n",
    "    for (idx, c_label) in enumerate(target_names):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
    "    c_ax.legend()\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "test_generator.reset()\n",
    "y_pred = model.predict_generator(test_generator, verbose = True)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(\"Multiclass roc auc score:\", multiclass_roc_auc_score(test_generator.classes, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. Model exportation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"models/CNN_baseline.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9. Plot model as graph of layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file='model.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
